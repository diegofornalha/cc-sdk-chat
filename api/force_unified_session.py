#!/usr/bin/env python3
"""
For√ßa TODAS as sess√µes para o arquivo unificado
Move conte√∫do de qualquer novo arquivo JSONL para 00000000-0000-0000-0000-000000000001.jsonl
e deleta os arquivos com UUIDs aleat√≥rios
"""

import os
import json
import time
import shutil
from pathlib import Path
from datetime import datetime
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# Session ID unificado
UNIFIED_SESSION_ID = "00000000-0000-0000-0000-000000000001"
PROJECT_PATH = Path.home() / ".claude" / "projects" / "-Users-2a--claude-cc-sdk-chat-api"

class ForceUnifiedSessionHandler(FileSystemEventHandler):
    def __init__(self):
        self.unified_file = PROJECT_PATH / f"{UNIFIED_SESSION_ID}.jsonl"
        self.processing = set()
        
    def on_created(self, event):
        """Quando um novo arquivo √© criado, move conte√∫do para o unificado"""
        if event.is_directory:
            return
            
        file_path = Path(event.src_path)
        
        # Se √© um arquivo JSONL e N√ÉO √© o unificado
        if file_path.suffix == '.jsonl' and file_path.name != f"{UNIFIED_SESSION_ID}.jsonl":
            print(f"\nüö® NOVO ARQUIVO DETECTADO: {file_path.name}")
            self.consolidate_file(file_path)
    
    def on_modified(self, event):
        """Quando um arquivo √© modificado, move conte√∫do novo para o unificado"""
        if event.is_directory:
            return
            
        file_path = Path(event.src_path)
        
        # Se √© um arquivo JSONL e N√ÉO √© o unificado
        if file_path.suffix == '.jsonl' and file_path.name != f"{UNIFIED_SESSION_ID}.jsonl":
            if str(file_path) not in self.processing:
                self.consolidate_file(file_path)
    
    def consolidate_file(self, source_file):
        """Move todo conte√∫do do arquivo para o unificado e depois deleta"""
        self.processing.add(str(source_file))
        
        try:
            # Aguarda arquivo estabilizar
            time.sleep(0.1)
            
            # L√™ conte√∫do do arquivo fonte
            lines_to_move = []
            if source_file.exists():
                with open(source_file, 'r') as f:
                    for line in f:
                        if line.strip():
                            try:
                                # Parse JSON e for√ßa session ID unificado
                                data = json.loads(line)
                                data['sessionId'] = UNIFIED_SESSION_ID
                                lines_to_move.append(json.dumps(data) + '\n')
                            except json.JSONDecodeError:
                                lines_to_move.append(line)
            
            if lines_to_move:
                # Adiciona ao arquivo unificado
                with open(self.unified_file, 'a') as f:
                    f.writelines(lines_to_move)
                
                print(f"  ‚úÖ Movidas {len(lines_to_move)} linhas para {UNIFIED_SESSION_ID}.jsonl")
                
                # Deleta arquivo original
                source_file.unlink()
                print(f"  üóëÔ∏è  Arquivo {source_file.name} deletado")
            
        except Exception as e:
            print(f"  ‚ùå Erro ao consolidar: {e}")
        finally:
            self.processing.discard(str(source_file))

def clean_existing_files():
    """Limpa e consolida arquivos existentes"""
    print("\nüßπ Limpando arquivos existentes...")
    
    unified_file = PROJECT_PATH / f"{UNIFIED_SESSION_ID}.jsonl"
    
    # Lista todos os arquivos JSONL exceto o unificado
    other_files = [f for f in PROJECT_PATH.glob("*.jsonl") 
                   if f.name != f"{UNIFIED_SESSION_ID}.jsonl"]
    
    if not other_files:
        print("  ‚úÖ Nenhum arquivo extra encontrado")
        return
    
    # Coleta todas as entradas
    all_entries = []
    
    # Primeiro, l√™ o arquivo unificado se existir
    if unified_file.exists():
        with open(unified_file, 'r') as f:
            for line in f:
                if line.strip():
                    try:
                        data = json.loads(line)
                        all_entries.append(data)
                    except:
                        pass
    
    # Depois, l√™ os outros arquivos
    for file in other_files:
        print(f"  üìÑ Processando: {file.name}")
        with open(file, 'r') as f:
            for line in f:
                if line.strip():
                    try:
                        data = json.loads(line)
                        # For√ßa session ID unificado
                        data['sessionId'] = UNIFIED_SESSION_ID
                        all_entries.append(data)
                    except:
                        pass
        
        # Deleta arquivo ap√≥s processar
        file.unlink()
        print(f"  üóëÔ∏è  Deletado: {file.name}")
    
    # Ordena por timestamp
    all_entries.sort(key=lambda x: x.get('timestamp', ''))
    
    # Reescreve arquivo unificado
    with open(unified_file, 'w') as f:
        for entry in all_entries:
            f.write(json.dumps(entry) + '\n')
    
    print(f"\n‚úÖ Consolidadas {len(all_entries)} entradas em {UNIFIED_SESSION_ID}.jsonl")
    print(f"üìÅ Arquivo √∫nico: {unified_file}")

def main():
    """Monitor principal que for√ßa sess√£o unificada"""
    print("=" * 60)
    print("üîí FOR√áANDO SESS√ÉO UNIFICADA")
    print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    print()
    print(f"üìÅ Monitorando: {PROJECT_PATH}")
    print(f"üéØ Arquivo √∫nico: {UNIFIED_SESSION_ID}.jsonl")
    print()
    
    # Garante que diret√≥rio existe
    PROJECT_PATH.mkdir(parents=True, exist_ok=True)
    
    # Garante que arquivo unificado existe
    unified_file = PROJECT_PATH / f"{UNIFIED_SESSION_ID}.jsonl"
    if not unified_file.exists():
        unified_file.touch()
        print(f"‚ú® Criado arquivo unificado: {unified_file.name}")
    
    # Limpa e consolida arquivos existentes
    clean_existing_files()
    
    # Configura monitor
    event_handler = ForceUnifiedSessionHandler()
    observer = Observer()
    observer.schedule(event_handler, str(PROJECT_PATH), recursive=False)
    
    # Inicia monitoramento
    observer.start()
    print("\nüëÅÔ∏è  Monitorando... Qualquer novo arquivo ser√° consolidado!")
    print("   Pressione Ctrl+C para parar")
    print()
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
        print("\nüõë Monitor parado")
    
    observer.join()

if __name__ == "__main__":
    main()